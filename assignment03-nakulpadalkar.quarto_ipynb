{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Assignment 03\n",
        "author:\n",
        "  - name: Norah Jones\n",
        "    affiliations:\n",
        "      - id: bu\n",
        "        name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "number-sections: true\n",
        "date: '2024-11-21'\n",
        "format:\n",
        "  html:\n",
        "    theme: cerulean\n",
        "    toc: true\n",
        "    toc-depth: 2\n",
        "  docx: default\n",
        "  pdf: default  \n",
        "execute: \n",
        "  freeze: auto\n",
        "date-modified: today\n",
        "date-format: long\n",
        "---\n",
        "\n",
        "# Load the Dataset\n",
        "The instruction below provides you with general keywords for columns used in the lightcast file. See the data schema generated after the load dataset code above to use proper column name. For each visualization, **customize colors, fonts, and styles** to avoid a **2.5-point deduction**. Also, **provide a two-sentence explanation** describing key insights drawn from the graph. \n",
        "\n",
        "1. **Load the Raw Dataset**:\n",
        "   - Use Pyspark to the `lightcast_data.csv` file into a DataFrame:\n",
        "   - You can reuse the previous code. \n",
        "   - [Copying code from your friend constitutes plagiarism. DO NOT DO THIS]{.bloodred-bold}."
      ],
      "id": "72a50b71"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: true\n",
        "#| echo: true\n",
        "#| fig-align: center\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = \"svg\"\n",
        "from pyspark.sql import SparkSession\n",
        "import re\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, monotonically_increasing_id\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "pio.renderers.default = \"notebook\"\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"LightcastData\").getOrCreate()\n",
        "\n",
        "# Load Data\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"multiLine\",\"true\").option(\"escape\", \"\\\"\").csv(\"./data/lightcast_job_postings.csv\")\n",
        "\n",
        "# Show Schema and Sample Data\n",
        "# print(\"---This is Diagnostic check, No need to print it in the final doc---\")\n",
        "\n",
        "# df.printSchema() # comment this line when rendering the submission\n",
        "# df.show(5)"
      ],
      "id": "90002a7a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Histogram of SALARY distribution\n",
        "fig = px.histogram(df.toPandas(), x=\"SALARY\", nbins=50, title=\"Salary Distribution\")\n",
        "fig.update_layout(bargap=0.1)"
      ],
      "id": "2645adcc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation"
      ],
      "id": "6a5099ba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 1: Casting salary and experience columns\n",
        "df = df.withColumn(\"SALARY\", col(\"SALARY\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_FROM\", col(\"SALARY_FROM\").cast(\"float\")) \\\n",
        "       .withColumn(\"SALARY_TO\", col(\"SALARY_TO\").cast(\"float\")) \\\n",
        "       .withColumn(\"MIN_YEARS_EXPERIENCE\", col(\"MIN_YEARS_EXPERIENCE\").cast(\"float\")) \\\n",
        "       .withColumn(\"MAX_YEARS_EXPERIENCE\", col(\"MAX_YEARS_EXPERIENCE\").cast(\"float\"))\n",
        "    \n",
        "    \n",
        "# Step 2: Computing medians for salary columns\n",
        "def compute_median(sdf, col_name):\n",
        "    q = sdf.approxQuantile(col_name, [0.5], 0.01)\n",
        "    return q[0] if q else None\n",
        "\n",
        "median_from = compute_median(df, \"SALARY_FROM\")\n",
        "median_to = compute_median(df, \"SALARY_TO\")\n",
        "\n",
        "print(\"Medians:\", median_from, median_to)\n",
        "\n",
        "# Step 3: Imputing missing salaries, but not experience\n",
        "df = df.fillna({\n",
        "    \"SALARY_FROM\": median_from,\n",
        "    \"SALARY_TO\": median_to\n",
        "})\n",
        "\n",
        "# Step 5: Computing average salary\n",
        "df = df.withColumn(\"Average_Salary\", (col(\"SALARY_FROM\") + col(\"SALARY_TO\")) / 2)\n",
        "\n",
        "# Step 6: Selecting required columns\n",
        "export_cols = [\n",
        "    \"EDUCATION_LEVELS_NAME\",\n",
        "    \"REMOTE_TYPE_NAME\",\n",
        "    \"MAX_YEARS_EXPERIENCE\",\n",
        "    \"Average_Salary\",\n",
        "    \"LOT_V6_SPECIALIZED_OCCUPATION_NAME\"\n",
        "]\n",
        "df_selected = df.select(*export_cols)\n",
        "\n",
        "# Step 7: Saving to CSV\n",
        "pdf = df_selected.toPandas()\n",
        "pdf.to_csv(\"./data/lightcast_cleaned.csv\", index=False)\n",
        "\n",
        "print(\" Data cleaning complete. Rows retained:\", len(pdf))"
      ],
      "id": "14ad25c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Salary Distribution by Industry and Employment Type\n",
        "- Compare salary variations across industries.\n",
        "- **Filter the dataset**\n",
        "  - Remove records where **salary is missing or zero**.\n",
        "- **Aggregate Data**\n",
        "  - Group by **NAICS industry codes**.\n",
        "  - Group by **employment type** and compute salary distribution.\n",
        "  - Calculate **salary percentiles** (25th, 50th, 75th) for each group.\n",
        "- **Visualize results**\n",
        "  - Create a **box plot** where:\n",
        "    - **X-axis** = `NAICS2_NAME`\n",
        "    - **Y-axis** = `SALARY_FROM`, or `SALARY_TO`, or `SALARY`\n",
        "    - Group by `EMPLOYMENT_TYPE_NAME`.\n",
        "  - Customize colors, fonts, and styles.\n",
        "- **Explanation:** Write two sentences about what the graph reveals.\n",
        "\n",
        "\n",
        "# Salary Analysis by ONET Occupation Type (Bubble Chart)\n",
        "- Analyze how salaries differ across ONET occupation types.\n",
        "- **Aggregate Data**\n",
        "  - Compute **median salary** for each occupation in the **ONET taxonomy**.\n",
        "- **Visualize results**\n",
        "  - Create a **bubble chart** where:\n",
        "    - **X-axis** = `ONET_NAME`\n",
        "    - **Y-axis** = `Median Salary`\n",
        "    - **Size** = Number of job postings\n",
        "  - Apply custom colors and font styles.\n",
        "- **Explanation:** Write two sentences about what the graph reveals.\n",
        "\n",
        "\n",
        "# Salary by Education Level\n",
        "\n",
        "- Create two groups:\n",
        "  - **Bachelor’s or lower** (Bachelor's, GED, Associate, No Education Listed)\n",
        "  - **Master’s or PhD** (Master's degree, Ph.D. or professional degree)\n",
        "- Plot scatter plots for each group using, `MAX_YEARS_EXPERIENCE` (with jitter), `Average_Salary`, `LOT_V6_SPECIALIZED_OCCUPATION_NAME`\n",
        "- Then, plot histograms overlaid with KDE curves for each group.\n",
        "- This would generate two scatter plots and two histograms.\n",
        "- **After each graph, add a short explanation** of key insights.\n",
        "\n",
        "# Salary by Remote Work Type\n",
        "- Split into three groups based on `REMOTE_TYPE_NAME`:\n",
        "  - Remote  \n",
        "  - Hybrid  \n",
        "  - Onsite (includes `[None]` and blank)\n",
        "- Plot scatter plots for each group using, `MAX_YEARS_EXPERIENCE` (with jitter), `Average_Salary`, `LOT_V6_SPECIALIZED_OCCUPATION_NAME`\n",
        "- Also, create salary histograms for all three groups.\n",
        "- **After each graph, briefly describe any patterns or comparisons.**"
      ],
      "id": "430ed18f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}